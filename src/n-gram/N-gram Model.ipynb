{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokenized Words for Bad Movies: 415959\n",
      "Number of Tokenized Words for Good Movies: 395602\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import os\n",
    "\n",
    "# This regex expression extracts only words. \n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Get the number format such as: 001, 002, 010, 100\n",
    "def getNum(i):\n",
    "    num = \"\"\n",
    "    if len(str(i)) == 1:\n",
    "        num = \"00\" + str(i)\n",
    "    if len(str(i)) == 2:\n",
    "        num = \"0\" + str(i)\n",
    "    if len(str(i)) == 3:\n",
    "        num = str(i)\n",
    "    return num\n",
    "\n",
    "# Return a tokensized text of the Transcripts and a raw text of the Transcripts\n",
    "def getMovieTranscripts(low = True):\n",
    "    movieScripts = []\n",
    "    text = \"\"\n",
    "    movieScores = \"\"\n",
    "    if low == True:\n",
    "        movieScores = \"low\"\n",
    "    else:\n",
    "        movieScores = \"high\"\n",
    "    #Taking advantage of the naming convension for the files, iterate through the files.\n",
    "    for i in list(range(1,101)):\n",
    "        #Check if the file exists.\n",
    "        if os.path.isfile('data\\\\'+ movieScores + '-rated\\\\' + getNum(i) + '-transcript.txt'): \n",
    "            f = open('data\\\\'+ movieScores + '-rated\\\\' + getNum(i) + '-transcript.txt', 'r')\n",
    "            content = f.read()\n",
    "            # Normalize the whitespaces and lowercase everything\n",
    "            newContent = \" \".join(content.lower().split())\n",
    "            text += newContent\n",
    "            movieScripts += tokenizer.tokenize(newContent)\n",
    "    return movieScripts, text\n",
    "\n",
    "badMovieScripts, badText = getMovieTranscripts(low = True)\n",
    "print(\"Number of Tokenized Words for Bad Movies:\", len(badMovieScripts))\n",
    "\n",
    "goodMovieScripts, goodText = getMovieTranscripts(low = False)\n",
    "print(\"Number of Tokenized Words for Good Movies:\", len(goodMovieScripts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest count after 'oh' is:  my\n",
      "oh shit 50\n",
      "oh my 240\n",
      "oh god 76\n",
      "oh boy 13\n",
      "oh man 35\n",
      "oh hey 27\n",
      "oh look 15\n",
      "oh you 53\n",
      "oh babe 1\n",
      "oh a 6\n",
      "oh hell 12\n",
      "oh no 126\n",
      "oh carrie 1\n",
      "oh baby 7\n",
      "oh what 18\n",
      "oh where 3\n",
      "oh i 116\n",
      "oh good 11\n",
      "oh come 29\n",
      "oh damn 6\n",
      "oh yeah 148\n",
      "oh do 6\n",
      "oh yes 28\n",
      "oh she 5\n",
      "oh that 50\n",
      "oh jesus 4\n",
      "oh wonderful 1\n",
      "oh so 13\n",
      "oh this 13\n",
      "oh okay 14\n",
      "oh it 35\n",
      "oh son 1\n",
      "oh and 17\n",
      "oh whoa 4\n",
      "oh archie 1\n",
      "oh they 3\n",
      "oh finally 1\n",
      "oh by 6\n",
      "oh kahuna 1\n",
      "oh honey 7\n",
      "oh how 7\n",
      "oh jeanette 1\n",
      "oh these 1\n",
      "oh right 11\n",
      "oh shucks 1\n",
      "oh dropped 1\n",
      "oh resistance 1\n",
      "oh oh 86\n",
      "oh excuse 6\n",
      "oh the 7\n",
      "oh he 9\n",
      "oh on 1\n",
      "oh well 12\n",
      "oh coopie 1\n",
      "oh about 1\n",
      "oh hi 15\n",
      "oh listen 2\n",
      "oh really 12\n",
      "oh lovers 1\n",
      "oh thanks 5\n",
      "oh fuck 3\n",
      "oh poopoo 1\n",
      "oh poo 1\n",
      "oh ah 3\n",
      "oh sweet 2\n",
      "oh snap 4\n",
      "oh morgan 1\n",
      "oh l 5\n",
      "oh wow 6\n",
      "oh never 1\n",
      "oh not 4\n",
      "oh crap 3\n",
      "oh gamsie 1\n",
      "oh 1167 1\n",
      "oh please 9\n",
      "oh 1174 1\n",
      "oh krishna 1\n",
      "oh dax 1\n",
      "oh 1478 1\n",
      "oh darlin 2\n",
      "oh but 10\n",
      "oh chuckles 1\n",
      "oh girl 1\n",
      "oh if 4\n",
      "oh very 3\n",
      "oh great 10\n",
      "oh bring 1\n",
      "oh lex 1\n",
      "oh sorry 7\n",
      "oh c 1\n",
      "oh thank 9\n",
      "oh ooh 5\n",
      "oh mr 5\n",
      "oh lucy 1\n",
      "oh say 1\n",
      "oh mmm 2\n",
      "oh dutch 1\n",
      "oh have 2\n",
      "oh bingo 1\n",
      "oh we 10\n",
      "oh bugger 1\n",
      "oh dear 7\n",
      "oh screw 2\n",
      "oh read 1\n",
      "oh heavenly 1\n",
      "oh harsh 1\n",
      "oh true 1\n",
      "oh uh 6\n",
      "oh don 3\n",
      "oh sh 2\n",
      "oh hmm 2\n",
      "oh wait 7\n",
      "oh tom 1\n",
      "oh bitches 1\n",
      "oh fabulous 2\n",
      "oh burn 1\n",
      "oh mulligan 1\n",
      "oh ohh 2\n",
      "oh somebody 1\n",
      "oh shoot 2\n",
      "oh think 2\n",
      "oh id 1\n",
      "oh that√¢ 2\n",
      "oh eat 1\n",
      "oh got 1\n",
      "oh nice 5\n",
      "oh its 2\n",
      "oh looking 1\n",
      "oh does 1\n",
      "oh let 1\n",
      "oh all 4\n",
      "oh pretty 2\n",
      "oh crazed 1\n",
      "oh little 3\n",
      "oh here 7\n",
      "oh whimpering 1\n",
      "oh why 6\n",
      "oh cheering 1\n",
      "oh simon 1\n",
      "oh sputters 1\n",
      "oh go 2\n",
      "oh oxy 1\n",
      "oh neutrogena 1\n",
      "oh ugly 1\n",
      "oh whispering 1\n",
      "oh watchin 1\n",
      "oh as 3\n",
      "oh hip 1\n",
      "oh groans 1\n",
      "oh ask 1\n",
      "oh groaning 1\n",
      "oh s 1\n",
      "oh ow 2\n",
      "oh leonidas 1\n",
      "oh roaring 1\n",
      "oh cute 1\n",
      "oh ain 1\n",
      "oh ominous 1\n",
      "oh isn 2\n",
      "oh mama 1\n",
      "oh behave 1\n",
      "oh grandma 1\n",
      "oh get 2\n",
      "oh dad 2\n",
      "oh grantulla 1\n",
      "oh stop 4\n",
      "oh jinxers 1\n",
      "oh elliot 2\n",
      "oh make 1\n",
      "oh michael 1\n",
      "oh lord 2\n",
      "oh kazoo 1\n",
      "oh back 1\n",
      "oh max 2\n",
      "oh r 1\n",
      "oh square 1\n",
      "oh just 5\n",
      "oh love 2\n",
      "oh is 2\n",
      "oh were 1\n",
      "oh of 1\n",
      "oh sure 10\n",
      "oh whatever 2\n",
      "oh piease 1\n",
      "oh meredith 1\n",
      "oh gross 2\n",
      "oh lone 1\n",
      "oh beautiful 1\n",
      "oh colonel 1\n",
      "oh buck 1\n",
      "oh jack 4\n",
      "oh will 3\n",
      "oh did 1\n",
      "oh strong 1\n",
      "oh tell 1\n",
      "oh pali 1\n",
      "oh cool 1\n",
      "oh coolness 1\n",
      "oh there 5\n",
      "oh felipe 2\n",
      "oh hold 2\n",
      "oh poopsie 1\n",
      "oh holy 1\n",
      "oh are 2\n",
      "oh geez 1\n",
      "oh who 2\n",
      "oh muleteers 1\n",
      "oh now 1\n",
      "oh barb 1\n",
      "oh mine 1\n",
      "oh hercules 1\n",
      "oh turn 1\n",
      "oh pack 1\n",
      "oh gosh 1\n",
      "oh dearie 1\n",
      "oh graydon 1\n",
      "oh err 1\n",
      "oh those 1\n",
      "oh your 1\n",
      "oh yea 1\n",
      "oh lucky 1\n",
      "oh whew 2\n",
      "oh aah 2\n",
      "oh much 1\n",
      "oh looks 2\n",
      "oh whoo 3\n",
      "oh taste 1\n",
      "oh wha 1\n",
      "oh night 1\n",
      "oh kantmiss 1\n",
      "oh peter 2\n",
      "oh give 1\n",
      "oh ready 1\n",
      "oh hello 4\n",
      "oh allow 1\n",
      "oh with 1\n",
      "oh tackleberry 1\n",
      "oh being 1\n",
      "oh weii 1\n",
      "oh pistachio 1\n",
      "oh wrong 1\n",
      "oh two 1\n",
      "oh would 1\n",
      "oh cheap 1\n",
      "oh joan 4\n",
      "oh tap 1\n",
      "oh mommy 1\n",
      "oh ho 2\n",
      "oh things 2\n",
      "oh sal 1\n",
      "oh cock 1\n",
      "oh teddy 1\n",
      "oh um 1\n",
      "oh ahhh 2\n",
      "oh be 1\n",
      "oh ahh 3\n",
      "oh for 3\n",
      "oh jeez 2\n",
      "oh in 2\n",
      "oh actually 1\n",
      "oh mask 1\n",
      "oh tick 1\n",
      "oh straight 1\n",
      "oh father 1\n",
      "oh valerie 1\n",
      "oh people 1\n",
      "oh chloe 1\n",
      "oh kate 2\n",
      "oh jamison 1\n",
      "oh cynthia 1\n",
      "oh hot 1\n",
      "oh tough 1\n",
      "oh shut 1\n",
      "oh drat 1\n",
      "oh norbit 2\n",
      "oh jeff 1\n",
      "oh him 1\n",
      "oh something 1\n",
      "oh edwards 1\n",
      "oh forget 1\n",
      "oh mario 2\n",
      "oh check 2\n",
      "oh later 1\n",
      "oh luigi 1\n",
      "oh courageously 1\n",
      "oh too 1\n",
      "oh mike 3\n",
      "oh like 3\n",
      "oh weird 1\n",
      "oh sweetie 1\n",
      "oh licking 1\n",
      "oh suck 1\n",
      "oh drop 1\n",
      "oh goodness 1\n",
      "oh goodie 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def createBigramCount(scripts):\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    bigrams = ngrams(scripts, 2)\n",
    "    for i in scripts:\n",
    "        for word1, word2 in bigrams:\n",
    "            model[word1][word2] += 1\n",
    "    return model\n",
    "\n",
    "model = createBigramCount(badMovieScripts)\n",
    "\n",
    "#The dictionary is structured like this: [word1 : [word2: Count(word2)]]\n",
    "word1 = 'oh'\n",
    "print(\"The highest count after 'oh' is: \", max(model[word1], key=model[word1].get))\n",
    "for word2 in model['oh']:\n",
    "    print(word1, word2, model['oh'][word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oh', 'my', 'god', 'i', 'm', 'not', 'a', 'little', 'bit', 'of', 'the', 'hell']\n"
     ]
    }
   ],
   "source": [
    "def bigramPredict(scripts, word, length):\n",
    "    bigramModel = createBigramCount(scripts)\n",
    "    sentence = word.split()\n",
    "    #print(np.random.choice(list(model[sentence[-1]]), 1, p = [float(i)/sum(model[sentence[-1]].values()) for i in model[sentence[-1]].values()]))\n",
    "    for i in range(length):\n",
    "        sentence.append(max(bigramModel[sentence[-1]], key=bigramModel[sentence[-1]].get))  \n",
    "        #sentence.append(np.random.choice(list(model[sentence[-1]]), 1, p = [float(i)/sum(model[sentence[-1]].values()) for i in model[sentence[-1]].values()])[0])  \n",
    "    return sentence\n",
    "\n",
    "print(bigramPredict(badMovieScripts, 'oh', 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest count after 'you, just' is:  got\n",
      "('you', 'just') got 8\n",
      "('you', 'just') walk 1\n",
      "('you', 'just') don 4\n",
      "('you', 'just') can 2\n",
      "('you', 'just') name 1\n",
      "('you', 'just') get 4\n",
      "('you', 'just') gonna 1\n",
      "('you', 'just') wish 1\n",
      "('you', 'just') say 3\n",
      "('you', 'just') drive 1\n",
      "('you', 'just') wait 1\n",
      "('you', 'just') have 2\n",
      "('you', 'just') do 3\n",
      "('you', 'just') kept 1\n",
      "('you', 'just') said 3\n",
      "('you', 'just') keep 1\n",
      "('you', 'just') found 1\n",
      "('you', 'just') never 2\n",
      "('you', 'just') heard 1\n",
      "('you', 'just') shut 1\n",
      "('you', 'just') go 1\n",
      "('you', 'just') wrecked 1\n",
      "('you', 'just') fart 1\n",
      "('you', 'just') hear 1\n",
      "('you', 'just') kissed 1\n",
      "('you', 'just') pop 1\n",
      "('you', 'just') had 2\n",
      "('you', 'just') you 1\n",
      "('you', 'just') leave 5\n",
      "('you', 'just') let 2\n",
      "('you', 'just') stuff 1\n",
      "('you', 'just') passing 1\n",
      "('you', 'just') stay 1\n",
      "('you', 'just') come 1\n",
      "('you', 'just') give 2\n",
      "('you', 'just') listen 2\n",
      "('you', 'just') taik 1\n",
      "('you', 'just') stop 1\n",
      "('you', 'just') iove 1\n",
      "('you', 'just') wanted 1\n",
      "('you', 'just') the 1\n",
      "('you', 'just') take 4\n",
      "('you', 'just') confess 1\n",
      "('you', 'just') met 1\n",
      "('you', 'just') trust 2\n",
      "('you', 'just') lay 1\n",
      "('you', 'just') sit 1\n",
      "('you', 'just') need 3\n",
      "('you', 'just') love 3\n",
      "('you', 'just') tell 1\n",
      "('you', 'just') better 1\n",
      "('you', 'just') die 1\n",
      "('you', 'just') cut 1\n",
      "('you', 'just') want 1\n",
      "('you', 'just') like 1\n",
      "('you', 'just') killed 1\n",
      "('you', 'just') stick 1\n",
      "('you', 'just') teii 1\n",
      "('you', 'just') lost 1\n",
      "('you', 'just') call 2\n",
      "('you', 'just') gotta 2\n",
      "('you', 'just') calm 1\n",
      "('you', 'just') assumed 1\n",
      "('you', 'just') so 1\n",
      "('you', 'just') relax 1\n",
      "('you', 'just') pretend 1\n",
      "('you', 'just') make 2\n",
      "('you', 'just') skin 1\n",
      "('you', 'just') between 1\n",
      "('you', 'just') spray 1\n",
      "('you', 'just') to 1\n",
      "('you', 'just') busted 1\n",
      "('you', 'just') turn 1\n",
      "('you', 'just') made 1\n",
      "('you', 'just') how 1\n",
      "('you', 'just') hold 1\n",
      "('you', 'just') wanna 1\n",
      "('you', 'just') set 1\n",
      "('you', 'just') break 1\n",
      "('you', 'just') did 1\n",
      "('you', 'just') saw 1\n"
     ]
    }
   ],
   "source": [
    "def createTrigramCount(scripts):\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    trigrams = ngrams(scripts, 3)\n",
    "    for i in scripts:\n",
    "        for word1, word2, word3 in trigrams:\n",
    "            model[(word1, word2)][word3] += 1\n",
    "    return model\n",
    "\n",
    "model = createTrigramCount(badMovieScripts)\n",
    "#The dictionary is structured like this: [(word1, word2) : [word 3: Count(word3)]]\n",
    "word1_word2 = ('you', 'just')\n",
    "print(\"The highest count after 'you, just' is: \", max(model[word1_word2], key=model[word1_word2].get))\n",
    "for word3 in model[word1_word2]:\n",
    "    print(word1_word2, word3, model[word1_word2][word3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fucking fucking knees on your head now rub them both in circles put your hand on your head now rub them both\n",
      " on the other side of the world is changed i remember the last time i ve got to be a little more\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def trigramPredict(scripts, word, length):\n",
    "    trigramModel = createTrigramCount(scripts)\n",
    "    sentence = bigramPredict(scripts, word, 1)\n",
    "    for i in range(length):\n",
    "        if len(trigramModel[(sentence[-2], sentence[-1])]) == 0:\n",
    "            sentence.append(bigramPredict(scripts, sentence[-1], 1)[-1])\n",
    "        else:\n",
    "            sentence.append(max(trigramModel[(sentence[-2], sentence[-1])], key=trigramModel[(sentence[-2], sentence[-1])].get))\n",
    "            #sentence.append(np.random.choice(list(trigramModel[(sentence[-2], sentence[-1])]), 1, p = [float(i)/sum(trigramModel[(sentence[-2], sentence[-1])].values()) for i in trigramModel[(sentence[-2], sentence[-1])].values()])[0])\n",
    "    return sentence\n",
    "\n",
    "\n",
    "result = trigramPredict(badMovieScripts, random.choice(badMovieScripts), 20)\n",
    "output1 = \"\"\n",
    "for i in result:\n",
    "    output1 += \" \" + i\n",
    "print(output1)\n",
    "\n",
    "result2 = trigramPredict(goodMovieScripts, random.choice(goodMovieScripts), 20)\n",
    "output2 = \"\"\n",
    "for i in result2:\n",
    "    output2 += \" \" + i\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
