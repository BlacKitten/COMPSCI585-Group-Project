{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokenized Words for Bad Movies: 714839\n",
      "Number of Tokenized Words for Good Movies: 994330\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "import os\n",
    "\n",
    "# Get the number format such as: 001, 002, 010, 100\n",
    "def getNum(i):\n",
    "    num = \"\"\n",
    "    if len(str(i)) == 1:\n",
    "        num = \"00\" + str(i)\n",
    "    if len(str(i)) == 2:\n",
    "        num = \"0\" + str(i)\n",
    "    if len(str(i)) == 3:\n",
    "        num = str(i)\n",
    "    return num\n",
    "\n",
    "# Return a tokensized text of the Transcripts and a raw text of the Transcripts\n",
    "def getMovieTranscripts(low = True):\n",
    "    movieScripts = []\n",
    "    movieScores = \"\"\n",
    "    if low == True:\n",
    "        movieScores = \"Bad\"\n",
    "    else:\n",
    "        movieScores = \"Good\"\n",
    "    #Taking advantage of the naming convension for the files, iterate through the files.\n",
    "    for i in list(range(1,101)):\n",
    "        #Check if the file exists.\n",
    "        if os.path.isfile('data\\\\Processed'+ movieScores + 'Scripts\\\\' + getNum(i) + '-transcript.txt'): \n",
    "            f = open('data\\\\Processed'+ movieScores + 'Scripts\\\\' + getNum(i) + '-transcript.txt', 'r')\n",
    "            content = f.read()\n",
    "            # Normalize the whitespaces and lowercase everything\n",
    "            newContent = \" \".join(content.lower().split())\n",
    "            movieScripts += nltk.word_tokenize(newContent)\n",
    "    return movieScripts\n",
    "\n",
    "badMovieScripts = getMovieTranscripts(low = True)\n",
    "print(\"Number of Tokenized Words for Bad Movies:\", len(badMovieScripts))\n",
    "\n",
    "goodMovieScripts = getMovieTranscripts(low = False)\n",
    "print(\"Number of Tokenized Words for Good Movies:\", len(goodMovieScripts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest count after 'oh' is:  ,\n",
      "oh , 1754\n",
      "oh no 12\n",
      "oh god 24\n",
      "oh my 86\n",
      "oh how 2\n",
      "oh . 167\n",
      "oh yeah 24\n",
      "oh right 2\n",
      "oh dropped 1\n",
      "oh on 1\n",
      "oh well 4\n",
      "oh coopie 1\n",
      "oh hey 10\n",
      "oh and 2\n",
      "oh okay 2\n",
      "oh hi 9\n",
      "oh listen 1\n",
      "oh really 1\n",
      "oh look 2\n",
      "oh shit 7\n",
      "oh fuck 1\n",
      "oh ! 209\n",
      "oh harsh 1\n",
      "oh burn 1\n",
      "oh i 10\n",
      "oh ohh 1\n",
      "oh you 3\n",
      "oh this 1\n",
      "oh think 1\n",
      "oh got 1\n",
      "oh nice 1\n",
      "oh oh 10\n",
      "oh damn 1\n",
      "oh does 1\n",
      "oh all 1\n",
      "oh here 2\n",
      "oh that 2\n",
      "oh people 1\n",
      "oh simon 1\n",
      "oh ugly 1\n",
      "oh : 1\n",
      "oh hello 1\n",
      "oh # 1\n",
      "oh mmm 1\n",
      "oh thanks 1\n",
      "oh cute 1\n",
      "oh ooh 1\n",
      "oh wait 1\n",
      "oh love 1\n",
      "oh we 2\n",
      "oh were 1\n",
      "oh yes 6\n",
      "oh honey 3\n",
      "oh dear 2\n",
      "oh beautiful 1\n",
      "oh now 2\n",
      "oh barb 1\n",
      "oh ? 6\n",
      "oh boy 3\n",
      "oh err 1\n",
      "oh right.. 1\n",
      "oh snap 1\n",
      "oh yea 1\n",
      "oh wait.. 1\n",
      "oh great 2\n",
      "oh peter 1\n",
      "oh ah 1\n",
      "oh what 1\n",
      "oh get 1\n",
      "oh but 1\n",
      "oh it 2\n",
      "oh leonard 1\n",
      "oh ms. 1\n",
      "oh very 1\n",
      "oh ready 1\n",
      "oh if 1\n",
      "oh fred 2\n",
      "oh dumdum 1\n",
      "oh hell 1\n",
      "oh thats 1\n",
      "oh jesus 1\n",
      "oh by 1\n",
      "oh sure 1\n",
      "oh ' 1\n",
      "oh forget 1\n",
      "oh a 1\n",
      "oh sorry 1\n",
      "oh too 1\n",
      "oh weird 1\n",
      "oh just 1\n",
      "oh l 1\n",
      "oh thank 1\n",
      "oh licking 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def createBigramCount(scripts):\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    bigrams = ngrams(scripts, 2)\n",
    "    for i in scripts:\n",
    "        for word1, word2 in bigrams:\n",
    "            model[word1][word2] += 1\n",
    "    return model\n",
    "\n",
    "model = createBigramCount(badMovieScripts)\n",
    "\n",
    "#The dictionary is structured like this: [word1 : [word2: Count(word2)]]\n",
    "for word2 in model['oh']:\n",
    "    print(word1, word2, model['oh'][word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bigramPredict(scripts, word, length):\n",
    "    bigramModel = createBigramCount(scripts)\n",
    "    sentence = word.split()\n",
    "    #print(np.random.choice(list(model[sentence[-1]]), 1, p = [float(i)/sum(model[sentence[-1]].values()) for i in model[sentence[-1]].values()]))\n",
    "    count = 0\n",
    "    punctuations = ['.', '!', '?']\n",
    "    while count < length:\n",
    "        #sentence.append(max(bigramModel[sentence[-1]], key=bigramModel[sentence[-1]].get))  \n",
    "        randomToken = np.random.choice(list(bigramModel[sentence[-1]]), 1, p = [float(i)/sum(bigramModel[sentence[-1]].values()) for i in bigramModel[sentence[-1]].values()])[0]\n",
    "        if randomToken in punctuations:\n",
    "            count += 1\n",
    "        sentence.append(randomToken)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest count after 'you, just' is:  got\n",
      "('you', 'just') got 12\n",
      "('you', 'just') walk 1\n",
      "('you', 'just') do 8\n",
      "('you', 'just') ca 4\n",
      "('you', 'just') name 1\n",
      "('you', 'just') get 4\n",
      "('you', 'just') gon 1\n",
      "('you', 'just') wish 1\n",
      "('you', 'just') say 3\n",
      "('you', 'just') drive 1\n",
      "('you', 'just') wait 1\n",
      "('you', 'just') have 3\n",
      "('you', 'just') kept 2\n",
      "('you', 'just') said 4\n",
      "('you', 'just') keep 1\n",
      "('you', 'just') found 1\n",
      "('you', 'just') never 3\n",
      "('you', 'just') heard 1\n",
      "('you', 'just') shut 1\n",
      "('you', 'just') go 1\n",
      "('you', 'just') wrecked 1\n",
      "('you', 'just') fart 1\n",
      "('you', 'just') hear 1\n",
      "('you', 'just') kissed 1\n",
      "('you', 'just') pop 1\n",
      "('you', 'just') had 2\n",
      "('you', 'just') leave 5\n",
      "('you', 'just') let 1\n",
      "('you', 'just') stuff 1\n",
      "('you', 'just') passing 1\n",
      "('you', 'just') stay 1\n",
      "('you', 'just') come 1\n",
      "('you', 'just') give 2\n",
      "('you', 'just') listen 2\n",
      "('you', 'just') taik 1\n",
      "('you', 'just') iove 1\n",
      "('you', 'just') wanted 2\n",
      "('you', 'just') the 1\n",
      "('you', 'just') take 5\n",
      "('you', 'just') confess 1\n",
      "('you', 'just') met 1\n",
      "('you', 'just') trust 2\n",
      "('you', 'just') lay 1\n",
      "('you', 'just') sit 1\n",
      "('you', 'just') need 4\n",
      "('you', 'just') love 3\n",
      "('you', 'just') tell 1\n",
      "('you', 'just') better 1\n",
      "('you', 'just') die 1\n",
      "('you', 'just') cut 1\n",
      "('you', 'just') want 2\n",
      "('you', 'just') like 1\n",
      "('you', 'just') killed 1\n",
      "('you', 'just') stick 1\n",
      "('you', 'just') teii 1\n",
      "('you', 'just') iet 1\n",
      "('you', 'just') ran 1\n",
      "('you', 'just') concentrate 1\n",
      "('you', 'just') don 2\n",
      "('you', 'just') earned 1\n",
      "('you', 'just') thought 1\n",
      "('you', 'just') saved 1\n",
      "('you', 'just') called 1\n",
      "('you', 'just') could 1\n",
      "('you', 'just') went 2\n",
      "('you', 'just') startled 1\n",
      "('you', 'just') leaving 1\n",
      "('you', 'just') tape 1\n",
      "('you', 'just') mentioned 1\n",
      "('you', 'just') wan 2\n",
      "('you', 'just') kiss 1\n",
      "('you', 'just') push 1\n",
      "('you', 'just') roll 1\n",
      "('you', 'just') rolled 1\n",
      "('you', 'just') marry 1\n",
      "('you', 'just') trying 1\n",
      "('you', 'just') mad 1\n",
      "('you', 'just') call 3\n",
      "('you', 'just') told 1\n",
      "('you', 'just') scrape 1\n",
      "('you', 'just') going 1\n",
      "('you', 'just') lost 1\n",
      "('you', 'just') calm 1\n",
      "('you', 'just') assumed 1\n",
      "('you', 'just') relax 1\n",
      "('you', 'just') pretend 1\n",
      "('you', 'just') skin 1\n",
      "('you', 'just') make 1\n",
      "('you', 'just') spray 1\n",
      "('you', 'just') to 1\n",
      "('you', 'just') busted 1\n",
      "('you', 'just') turn 1\n",
      "('you', 'just') made 1\n",
      "('you', 'just') how 1\n",
      "('you', 'just') hold 1\n",
      "('you', 'just') set 1\n",
      "('you', 'just') break 1\n",
      "('you', 'just') did 1\n",
      "('you', 'just') saw 1\n"
     ]
    }
   ],
   "source": [
    "def createTrigramCount(scripts):\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    trigrams = ngrams(scripts, 3)\n",
    "    for i in scripts:\n",
    "        for word1, word2, word3 in trigrams:\n",
    "            model[(word1, word2)][word3] += 1\n",
    "    return model\n",
    "\n",
    "model = createTrigramCount(badMovieScripts)\n",
    "#The dictionary is structured like this: [(word1, word2) : [word 3: Count(word3)]]\n",
    "word1_word2 = ('you', 'just')\n",
    "print(\"The highest count after 'you, just' is: \", max(model[word1_word2], key=model[word1_word2].get))\n",
    "for word3 in model[word1_word2]:\n",
    "    print(word1_word2, word3, model[word1_word2][word3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def trigramPredict(scripts, word, length):\n",
    "    bigramModel = createBigramCount(scripts)\n",
    "    trigramModel = createTrigramCount(scripts)\n",
    "    sentence = []\n",
    "    sentence.append(word)\n",
    "    sentence.append(np.random.choice(list(bigramModel[word]), 1, p = [float(i)/sum(bigramModel[word].values()) for i in bigramModel[word].values()])[0])\n",
    "    count = 0\n",
    "    punctuations = ['.', '!', '?']\n",
    "    while count < length:\n",
    "        if len(trigramModel[(sentence[-2], sentence[-1])]) == 0:\n",
    "            pick = np.random.choice(list(bigramModel[sentence[-1]]), 1, p = [float(i)/sum(bigramModel[sentence[-1]].values()) for i in bigramModel[sentence[-1]].values()])[0]\n",
    "            if pick in punctuations:\n",
    "                count += 1\n",
    "            sentence.append(pick)\n",
    "        else:\n",
    "            #sentence.append(max(trigramModel[(sentence[-2], sentence[-1])], key=trigramModel[(sentence[-2], sentence[-1])].get))\n",
    "            randomToken = np.random.choice(list(trigramModel[(sentence[-2], sentence[-1])]), 1, p = [float(i)/sum(trigramModel[(sentence[-2], sentence[-1])].values()) for i in trigramModel[(sentence[-2], sentence[-1])].values()])[0]\n",
    "            if randomToken in punctuations:\n",
    "                count += 1\n",
    "            sentence.append(randomToken)\n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram\n",
      "The bliss, tuesday. Ragged, you and wrapups.\n",
      "The waiting that's nothing that? He is this random, because we're trying to you have peace, or a second darkness, let yourself the gun in jeopardy!\n",
      "Trigram\n",
      "The fish is fresh, bouncing off the bed! You drew that?\n",
      "The stairs, picks up a cd case from a vendor in the distance, a girl from the ground in bright balls of flames. Alfredo pay attention.\n"
     ]
    }
   ],
   "source": [
    "def generate(ls):\n",
    "    output = \"\"\n",
    "    for token in ls:\n",
    "        if len(output) == 0:\n",
    "            output += token.capitalize()\n",
    "        elif output[-1] in ['.', '!', '?'] or token == 'i':\n",
    "            output += \" \" + token.capitalize()\n",
    "        elif token in [',', ':', '.', '!', '?'] or token[0] == \"'\" or token == \"n't\":\n",
    "            output += token\n",
    "        else:\n",
    "            output += \" \" + token\n",
    "    return output\n",
    "\n",
    "print(\"Bigram\")\n",
    "print(generate(bigramPredict(badMovieScripts, 'the', 2)))\n",
    "print(generate(bigramPredict(goodMovieScripts, 'the', 2)))\n",
    "\n",
    "print(\"Trigram\")\n",
    "print(generate(trigramPredict(badMovieScripts, 'the', 2)))\n",
    "print(generate(trigramPredict(goodMovieScripts, 'the', 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
